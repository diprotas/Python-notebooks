{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def greeting():\n",
    "    opts = { \"hey\" : ('Привет', 'Здравствуйте', 'Доброе утро', 'Добрый день', 'Добрый вечер', 'Доброй ночи')}\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    #now += timedelta(hours = 3) # можешь проверить тут\n",
    "    #print(now)\n",
    "    if now.hour > 4 and now.hour <= 12 :\n",
    "        greet = opts[\"hey\"][2]\n",
    "    if now.hour > 12 and now.hour <= 16 :\n",
    "        greet = opts[\"hey\"][3]\n",
    "    if now.hour > 16 and now.hour <= 24 :\n",
    "        greet = opts[\"hey\"][4]\n",
    "    if now.hour >= 0 and now.hour <= 4 :\n",
    "        greet = opts[\"hey\"][5]\n",
    "    return greet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "# удаляет повторные буквы: пппрррииивеееет -----> привет\n",
    "\n",
    "#def del_repeat(text):\n",
    "#    return ''.join(c[0] for c in itertools.groupby(text))\n",
    "\n",
    "\n",
    "# функция очищает текст\n",
    "def clean(text):    \n",
    "    text = text.lower() # приводит текст к нижнему регистру\n",
    "    #text = del_repeat(text)\n",
    "    cleaned_text = ''\n",
    "    for ch in text:\n",
    "        if ch in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя-—1234567890 ':\n",
    "             cleaned_text = cleaned_text + ch\n",
    "        \n",
    "    return cleaned_text\n",
    "\n",
    "# функция очищает текст\n",
    "def clean1(text):    \n",
    "    text = text.lower() # приводит текст к нижнему регистру\n",
    "    #text = del_repeat(text)\n",
    "    cleaned_text = ''\n",
    "    for ch in text:\n",
    "        if ch in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя1234567890,.:;!?_-—() ':\n",
    "             cleaned_text = cleaned_text + ch\n",
    "    return cleaned_text\n",
    "\n",
    "# транслитерация\n",
    "def cyrillic2latin(text):\n",
    "    cyrillic = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "    latin = 'a|b|v|g|d|e|e|zh|z|i|i|k|l|m|n|o|p|r|s|t|u|f|kh|tc|ch|sh|shch||y||e|iu|ia'.split('|')\n",
    "    trantab = {k:v for k,v in zip(cyrillic,latin)}\n",
    "    newtext = ''\n",
    "    for ch in text:\n",
    "        casefunc =  str.capitalize if ch.isupper() else str.lower\n",
    "        newtext += casefunc(trantab.get(ch.lower(),ch))\n",
    "    return newtext\n",
    "\n",
    "# №2\n",
    "def cyrillic2latin2(text):\n",
    "    cyrillic = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ'\n",
    "    latin = 'a|b|v|g|d|e|e|zh|z|i|i|k|l|m|n|o|p|r|s|t|u|f|kh|tc|ch|sh|shch||y||e|iu|ia|A|B|V|G|D|E|E|Zh|Z|I|I|K|L|M|N|O|P|R|S|T|U|F|Kh|Tc|Ch|Sh|Shch||Y||E|Iu|Ia'.split('|')    \n",
    "    return text.translate({ord(k):v for k,v in zip(cyrillic,latin)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# функция очищает текст\n",
    "def clean0(text):    \n",
    "    text = text.lower() # приводит текст к нижнему регистру\n",
    "    #text = del_repeat(text)\n",
    "    cleaned_text = ''\n",
    "    for ch in text:\n",
    "        if ch in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя-—':\n",
    "             cleaned_text = cleaned_text + ch\n",
    "        else:\n",
    "             cleaned_text = cleaned_text + ' '\n",
    "    return cleaned_text\n",
    "\n",
    "# очищаем запрос от стоп слов\n",
    "def clear_text_stop_words(text, stop_words_list):\n",
    "    text_tokens = word_tokenize(text)\n",
    "\n",
    "    clear_data=[]\n",
    "    for i in text_tokens:\n",
    "        i = clean0(i)\n",
    "        if i not in stop_words_list:\n",
    "            clear_data.append(i)\n",
    "    clear_data = sorted(set(clear_data))\n",
    "    clear_text = ' '.join(clear_data)\n",
    "    return clear_text    \n",
    "\n",
    "\n",
    "# лемматизация \n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def text_to_normal_form(text, morph = morph):\n",
    "    \n",
    "    text2 = word_tokenize(text) # Список слов предложения s        \n",
    "    s = ''\n",
    "    for word in text2:\n",
    "        word = morph.parse(word)[0].normal_form        \n",
    "        s += (' ' + word)        \n",
    "    \n",
    "    s1 = ' '.join(sorted(list(set(s.split()))))    \n",
    "    return s1.lstrip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#собираю нормализованную БЗ в HIST_BOT_CONFIG_NORM.json\n",
    "#продвинутая версия\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "def file_intents_norm(file_in):\n",
    "    #file_in = file_in\n",
    "    file_content = ''\n",
    "    \n",
    "    file_content += '{\\n'        \n",
    "    file_content += ('    \"intents\": {\\n')\n",
    "    list_intents = list(HIST_BOT_CONFIG['intents'].keys())\n",
    "    k = len(list_intents)\n",
    "    for j in range(0,k): \n",
    "        intent = list_intents[j]\n",
    "        file_content += ('       \\\"{}\\\" : {{\\n'.format(intent))        \n",
    "        file_content += ('           \"examples\" : [\\n')\n",
    "\n",
    "        m = len(HIST_BOT_CONFIG['intents'][intent]['examples'])\n",
    "        for i in range(0,m):\n",
    "            example = HIST_BOT_CONFIG['intents'][intent]['examples'][i]\n",
    "            clear_example = clear_text_stop_words(example, stop_words)\n",
    "            #clean_example = clean1(clear_example)            \n",
    "            clean_norm_example = text_to_normal_form(clear_example)\n",
    "            if i < m-1:\n",
    "                file_content += ('              \\\"{}\\\",\\n'.format(clean_norm_example))\n",
    "            else:\n",
    "                file_content += ('              \\\"{}\\\"\\n'.format(clean_norm_example))\n",
    "        \n",
    "        file_content += ('         ],\\n')\n",
    "        file_content += ('           \"responses\" : [\\n')\n",
    "\n",
    "        #разбиваю response на список предложений  20.11\n",
    "        list_responses = HIST_BOT_CONFIG['intents'][intent]['responses']\n",
    "        n = len(list_responses)\n",
    "        for p in range(0,n):\n",
    "            response = list_responses[p]\n",
    "            list_sentences = sent_tokenize(response, language=\"russian\") #разбиваем справку на предложения\n",
    "            m = len(list_sentences)\n",
    "            for i in range(0,m):            \n",
    "                sentence = list_sentences[i]            \n",
    "                clear_sentence = clear_text_stop_words(sentence, stop_words)                 \n",
    "                clean_norm_sentence = text_to_normal_form(clear_sentence)                \n",
    "                \n",
    "                if (p == n-1) and (i == m-1) :\n",
    "                    file_content += ('              \\\"{}\\\"\\n'.format(clean_norm_sentence))    \n",
    "                else:\n",
    "                    file_content += ('              \\\"{}\\\",\\n'.format(clean_norm_sentence))\n",
    "\n",
    "        file_content +=('         ]\\n')\n",
    "        if j < (k - 1):\n",
    "            file_content += ('      },\\n')\n",
    "        else:\n",
    "            file_content += ('      }\\n')\n",
    "\n",
    "    file_content += ('''\n",
    "\n",
    "\n",
    "\n",
    "      },\n",
    "\n",
    "    \"default\": [\n",
    "      \"Слишком много слов, напиши главное слово (словосочетание). Проверь, нет ли в слове опечатки?\",\n",
    "      \"Что-то непонятно. Составь вопрос из двух-трех слов. Проверь, нет ли в слове опечатки?\",\n",
    "      \"Сформулируйте попроще. Мне достаточно двух-трёх слов. Проверь, нет ли в слове опечатки?\",      \n",
    "      \"Сформулируйте попроще или поточнее.  Мне будет достаточно одного-двух или трёх слов. Проверь, нет ли в слове опечатки?\"\n",
    "   ],\n",
    "   \"default1\": [\n",
    "      \"Уточняющую информацию можно получить, если в запрос ввести непонятные слова из моих ответов\"\n",
    "   ]\n",
    "}\n",
    "        ''')\n",
    "    \n",
    "    \n",
    "\n",
    "    #записываем конструкцию в файл\n",
    "    with open(file_in, 'w', encoding='utf-8') as fin:\n",
    "        fin.write(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# новые поисковые функции версия 2\n",
    "\n",
    "import nltk\n",
    "import random\n",
    "from fuzzywuzzy import fuzz\n",
    "import Levenshtein as lev\n",
    "from functools import reduce\n",
    "import math \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------движок--по--БаЗе-болтовни--------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def get_chat_intent(text):   \n",
    "    for intent in BOT_CONFIG['intents'].keys():\n",
    "        for example in BOT_CONFIG['intents'][intent]['examples']:\n",
    "            clean_example = clean0(example)\n",
    "            clean_text = clean0(text)                        \n",
    "            if clean_example == clean_text:\n",
    "                return intent\n",
    "    return get_chat_intent1(text)\n",
    "\n",
    "\n",
    "\n",
    "def get_chat_intent1(text):   \n",
    "    for intent in BOT_CONFIG['intents'].keys():\n",
    "        for example in BOT_CONFIG['intents'][intent]['examples']:\n",
    "            clean_example = clean0(example)\n",
    "            clean_text = clean0(text)\n",
    "            clean_norm_example = text_to_normal_form(clean_example,morph)\n",
    "            clean_norm_text = text_to_normal_form(clean_text,morph)\n",
    "            if clean_norm_example == clean_norm_text:\n",
    "                return intent            \n",
    "            elif nltk.edit_distance(clean_example,clean_text)/len(clean_text) <.4:\n",
    "                return intent\n",
    "            elif nltk.edit_distance(clean_norm_example,clean_norm_text)/len(clean_norm_text)<.4:\n",
    "                return intent\n",
    "    return 'unknown_intent'\n",
    "\n",
    "# ===========движок--по--БЗ-по-истории=================================================\n",
    "\n",
    "# ---------------------функция сравнения строки и списка предложений------------------\n",
    "\n",
    "#clean_norm_text - запрос, list_sentens = HIST_BOT_CONFIG_NORM['intents'][intent]['examples']\n",
    "def metric_text_in_sentences(clean_norm_text,list_sentens):\n",
    "    results_list = []\n",
    "        \n",
    "    metric = 0\n",
    "    count_sentences = 0\n",
    "    metric_max = 0\n",
    "    count_max = 0\n",
    "    for clean_norm_example in list_sentens: #HIST_BOT_CONFIG_NORM['intents'][intent]['examples']:            \n",
    "            \n",
    "            diff_len = abs(len(clean_norm_text) - len(clean_norm_example))\n",
    "            \n",
    "            list_clean_norm_example = clean_norm_example.split()\n",
    "            list_clean_norm_text = clean_norm_text.split()\n",
    "            \n",
    "            len_example = len(list_clean_norm_example)\n",
    "            len_text = len(list_clean_norm_text)\n",
    "            \n",
    "            # для каждого чистого экзампла считается 3 метрики Левенштейна\n",
    "            dist_norm0 = fuzz.token_sort_ratio(clean_norm_example,clean_norm_text)\n",
    "            dist_norm1 = lev.ratio(clean_norm_example,clean_norm_text)*100\n",
    "            dist_norm = fuzz.token_set_ratio(clean_norm_text, clean_norm_example)\n",
    "            if dist_norm > 60:\n",
    "                print(clean_norm_text,'|', clean_norm_example,'|', dist_norm)\n",
    "            total_quadr_aver_dist = ((dist_norm0**2+dist_norm1**2+dist_norm**2)/3)**(1/2)\n",
    "            \n",
    "            if (dist_norm0*dist_norm1*dist_norm) and (total_quadr_aver_dist > 70):\n",
    "                \n",
    "                total_harm_aver_dist = 3/(1/dist_norm0+1/dist_norm1+1/dist_norm)\n",
    "                total_geom_aver_dist = (dist_norm0*dist_norm1*dist_norm)**(1/3)\n",
    "                total_sum_aver_dist = (dist_norm0+dist_norm1+dist_norm)/3                \n",
    "                \n",
    "                \n",
    "                total_diff_metric = total_quadr_aver_dist - total_harm_aver_dist           \n",
    "                \n",
    "                if (len_text <= len_example) and (dist_norm > 90):\n",
    "                    metric_max += dist_norm0\n",
    "                    count_max += 1\n",
    "                    \n",
    "                             \n",
    "                elif (len_text <= len_example) and (dist_norm > 75):\n",
    "                #if (dist_norm > 75):\n",
    "                    # кумулятивная метрика экзамплов для одного интента\n",
    "                    metric += dist_norm\n",
    "                    count_sentences += 1\n",
    "                results_list.append([dist_norm, clean_norm_example])\n",
    "                    #results_exam.append([total_quadr_aver_dist, clean_norm_example])                    \n",
    "                    \n",
    "            elif (len_text == len_example == 1) and (dist_norm0 > 65):\n",
    "                \n",
    "                if dist_norm0 > 90:\n",
    "                    metric_max += dist_norm0\n",
    "                    count_max += 1\n",
    "                else:\n",
    "                #print('dist_norm =',dist_norm, 'dist_norm0 =', dist_norm0)\n",
    "                # кумулятивная метрика экзамплов для одного интента\n",
    "                    metric += dist_norm0\n",
    "                    count_sentences += 1\n",
    "                results_list.append([dist_norm0, clean_norm_example])\n",
    "    try:\n",
    "        res = metric * count_sentences/len(list_sentens)\n",
    "    except:\n",
    "        res = 0\n",
    "        \n",
    "    try:\n",
    "        res_max = metric_max/count_max\n",
    "    except:\n",
    "        res_max = 0\n",
    "    \n",
    "    return res + res_max\n",
    "\n",
    "#------------------------------\n",
    "#ОСНОВНОЙ ПОИСК ПО НОРМАЛИЗОВАННЫМ EXAMPLAM и RESPONSAM в HIST_BOT_CONFIG_NORM.json\n",
    "def get_hist_intent(clean_norm_text, text, stop_words):\n",
    "    results_int = []\n",
    "    \n",
    "    for intent in HIST_BOT_CONFIG_NORM['intents'].keys(): \n",
    "        list_sentens_examples = HIST_BOT_CONFIG_NORM['intents'][intent]['examples']        \n",
    "        total_examples_metric = metric_text_in_sentences(clean_norm_text,list_sentens_examples)\n",
    "        \n",
    "        list_sentens_responses = HIST_BOT_CONFIG_NORM['intents'][intent]['responses']        \n",
    "        total_responses_metric = metric_text_in_sentences(clean_norm_text,list_sentens_responses)\n",
    "        \n",
    "        #results_int.append([dist_intent+total_examples_metric, intent])\n",
    "        total_intent_metric = total_examples_metric + total_responses_metric\n",
    "        results_int.append([total_intent_metric, intent])\n",
    "    \n",
    "    # находим минимальное расстояние в непустом массиве избранных интентов    \n",
    "        \n",
    "    results_int.sort(key = lambda pair: pair[0],reverse = True)\n",
    "    print('--'*25)\n",
    "    print('results_int',results_int[:15])\n",
    "    print('--'*25)\n",
    "    #text2voice(\"Фууфффф... Я очень сильно думала и вот что надумала: \")\n",
    "    #print(\"Бутя: Фууфффф... Я очень сильно думала и вот что надумала: \") \n",
    "\n",
    "    #выдача\n",
    "    if (len(results_int)>1) and (results_int[0][0] - results_int[1][0]) < 0.1:\n",
    "        intent = random.choice(results_int[:2])[1] #неуверенный вывод 17.11\n",
    "    else:\n",
    "        intent = results_int[0][1]\n",
    "\n",
    "    #intent = results_int[0][1]\n",
    "    #intent = random.choice(results_int[:2])[1] #неуверенный вывод решил использовать 17.11      \n",
    "\n",
    "    return intent      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основа"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# функция текст2речь\n",
    "import pyttsx3\n",
    "\n",
    "def text2voice(text):\n",
    "    tts = pyttsx3.init()\n",
    "    voices = tts.getProperty('voices')\n",
    "    # Задать голос по умолчанию\n",
    "    tts.setProperty('voice', 'ru') \n",
    "    # установить предпочтительный голос\n",
    "    voice.name == 'Vocalizer Expressive Katya Harpo 22kHz':\n",
    "    tts.setProperty('voice', voice.id)\n",
    "    tts.say(text)\n",
    "    tts.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia, re\n",
    "# Устанавливаем русский язык в Wikipedia\n",
    "wikipedia.set_lang(\"ru\")\n",
    "# Чистим текст статьи в Wikipedia и ограничиваем его тысячей символов\n",
    "def getwiki(s):\n",
    "    try:\n",
    "        ny = wikipedia.page(s)\n",
    "        # Получаем первую тысячу символов\n",
    "        wikitext=ny.content[:1000]\n",
    "        # Разделяем по точкам\n",
    "        wikimas=wikitext.split('.')\n",
    "        # Отбрасываем всЕ после последней точки\n",
    "        wikimas = wikimas[:-1]\n",
    "        # Создаем пустую переменную для текста\n",
    "        wikitext2 = ''\n",
    "        # Проходимся по строкам, где нет знаков «равно» (то есть все, кроме заголовков)\n",
    "        for x in wikimas:\n",
    "            if not('==' in x):\n",
    "        # Если в строке осталось больше трех символов, добавляем ее к нашей переменной и возвращаем утерянные при разделении строк точки на место\n",
    "                if(len((x.strip()))>3):\n",
    "                    wikitext2=wikitext2+x+'.'\n",
    "            else:\n",
    "                break\n",
    "        # Теперь при помощи регулярных выражений убираем разметку\n",
    "        wikitext2=re.sub('\\([^()]*\\)', '', wikitext2)\n",
    "        wikitext2=re.sub('\\([^()]*\\)', '', wikitext2)\n",
    "        wikitext2=re.sub('\\{[^\\{\\}]*\\}', '', wikitext2)\n",
    "        # Возвращаем текстовую строку\n",
    "        return wikitext2\n",
    "    # Обрабатываем исключение, которое мог вернуть модуль wikipedia при запросе\n",
    "    except Exception as e:\n",
    "        return random.choice(HIST_BOT_CONFIG['default'])+' (-)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transliterate import translit\n",
    "import time\n",
    "\n",
    "\n",
    "def bot(text, stop_words):\n",
    "    text = text.lower()#translit(text, 'ru')\n",
    "    \n",
    "    # Если пользователь здоровается\n",
    "    if text in ('хай','хей','хаюшки','здрасьте','привет', 'здравствуйте', 'доброе утро', 'добрый день', 'добрый вечер', 'доброй ночи','приветствую'):\n",
    "         return greeting(),\"Hellow\"       \n",
    "    \n",
    "    # Если пользователь не здоровается, тогда мы понимаем, что он делает запрос\n",
    "    else: \n",
    "        \n",
    "        \n",
    "        #intent1 = get_chat_intent(text)        \n",
    "        #print('get_chat_intent:',intent1)\n",
    "        \n",
    "        # очищаем запрос от стоп слов\n",
    "        clear_text = clear_text_stop_words(text, stop_words)\n",
    "        print('--'*20)\n",
    "        print('Очищенный запрос: ',clear_text)\n",
    "        print('--'*20)\n",
    "        #--------------------------------------\n",
    "        \n",
    "        # нормализуем очищенный запрос\n",
    "        #clean_text = clean0(clear_text)\n",
    "        clean_norm_text = text_to_normal_form(clear_text)\n",
    "        \n",
    "        print('--'*20)\n",
    "        print('Нормализованный запрос: ',clean_norm_text)\n",
    "        print('--'*20)\n",
    "        #--------------------------------------\n",
    "        \n",
    "        intent = get_hist_intent(clean_norm_text, text, stop_words)\n",
    "        \n",
    "\n",
    "        if (intent != 'unknown_intent') and (intent != 'default1'):\n",
    "            answer = random.choice(HIST_BOT_CONFIG['intents'][intent]['responses'])\n",
    "        elif intent == 'default1':\n",
    "             answer = HIST_BOT_CONFIG['default1'][0]\n",
    "        else:\n",
    "            intent1 = get_chat_intent(text)\n",
    "            if intent1 != 'unknown_intent':\n",
    "                answer = random.choice(BOT_CONFIG['intents'][intent1]['responses'])\n",
    "            else:                \n",
    "                answer = getwiki(clean_norm_text)\n",
    "                #answer = random.choice(HIST_BOT_CONFIG['default'])+' (-)'\n",
    "    \n",
    "    return answer, intent\n",
    "                \n",
    "\n",
    "def main_bot(input_text):\n",
    "    fin1 = open('data/chat_bot/quiest_respons.txt', 'a', encoding='utf-8') \n",
    "    #todo как быть, когда одновременно несколько человек общается с ботом\n",
    "    # вероятно для каждого usera надо создать отдельный лог-файл\n",
    "    fin1.write(str( datetime.datetime.now() )+'\\n')\n",
    "    #input_text = input('Введите запрос или нажмите Enter для выхода: ')\n",
    "    \n",
    "    # открываю и читаю файл со стоп-словами - создаю отсортированный список стоп-слов\n",
    "    stop_words = open('data/chat_bot/stop-ru.txt', 'r', encoding='utf8')\n",
    "    stop_words = stop_words.read()\n",
    "    stop_words = sorted(list(set(stop_words.split('\\n'))))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #while input_text:   \n",
    "    start_time = time.time()\n",
    "    #print('начальное время:', start)\n",
    "    response = bot(input_text, stop_words)#, fin1 = fin1)    \n",
    "\n",
    "    print('время ожидания:', time.time() - start_time)\n",
    "    print('{}'.format(response[0]) )\n",
    "    print('--'*20)\n",
    "    #text2voice(response)\n",
    "    fin1.write(str(datetime.datetime.now())[11:19]+' User: '+input_text+' | '+'Бот: '+response[0]+' | '+response[1]+'\\n')\n",
    "    #input_text = input('Введите запрос или нажмите Enter для выхода: ')\n",
    "    #print('До свидания')\n",
    "    #bye_text = random.choice(BOT_CONFIG['intents']['by_seeyou']['responses'])\n",
    "    #text2voice(bye_text)                     \n",
    "    #print(bye_text)\n",
    "    fin1.close()\n",
    "    return response[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Открываем базу знаний (в т.ч. нормализованная) по предметной области"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "import json\n",
    "# база болтовни\n",
    "with open ('data/chat_bot/BOT_CONFIG.json', 'r', encoding='utf-8') as f:\n",
    "    BOT_CONFIG = json.load(f)\n",
    "\n",
    "# база знаний по истории\n",
    "with open ('data/chat_bot/HIST_BOT_CONFIG.json', 'r', encoding='utf-8') as f_hist:\n",
    "    HIST_BOT_CONFIG = json.load(f_hist)  \n",
    "\n",
    "#база русских стоп-слов    \n",
    "stop_words = open('data/chat_bot/stop-ru.txt', 'r', encoding='utf8')\n",
    "stop_words = stop_words.read()\n",
    "stop_words = sorted(list(set(stop_words.split('\\n')))) \n",
    "\n",
    "#file_intents_norm('data/skillbox/HIST_BOT_CONFIG_NORM.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализованная база знаний по истории\n",
    "with open ('data/chat_bot/HIST_BOT_CONFIG_NORM.json', 'r', encoding='utf-8') as f_hist_norm:\n",
    "    HIST_BOT_CONFIG_NORM = json.load(f_hist_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### запускаем Геродбота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update.message.text: Привет\n",
      "время ожидания: 0.0\n",
      "Добрый день\n",
      "----------------------------------------\n",
      "update.message.text: Как дела?\n",
      "----------------------------------------\n",
      "Очищенный запрос:   \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Нормализованный запрос:  \n",
      "----------------------------------------\n",
      "--------------------------------------------------\n",
      "results_int [[0.0, 'sobiratelstvo_drevnickh_vyzhivanie'], [0.0, 'oxota_drevnickh_vyzhivanie'], [0.0, 'vyzhivanie_drevniy_predki'], [0.0, 'calculus_drevniy_predki'], [0.0, 'obraz_gizni'], [0.0, 'techenia_reki_Kakoe'], [0.0, 'zemledelie_dvukh_Kakoe'], [0.0, 'rodovaia_sosedskaiy_obchina_8786234'], [0.0, 'okhotnikov_bylo_Pochemu'], [0.0, 'Zeronoterka_Zeronoterka_Zeronoterka'], [0.0, 'Priadenie_Priadenie_Priadenie'], [0.0, 'Tkachestvo_Tkachestvo_Tkachestvo'], [0.0, 'Tcinovka_Tcinovka_Tcinovka'], [0.0, 'Dukhi_Dukhi_Dukhi'], [0.0, 'Bogi_Bogi_Bogi']]\n",
      "--------------------------------------------------\n",
      "время ожидания: 0.7780013084411621\n",
      "Древнейшие люди добывали пищу собирательством. Собирательство: это в основном женское занятие. Целыми днями первобытные люди собиратели занимались собирательством: искали съедобные грибы, ягоды, коренья и улиток, плоды растений и деревьев: орехи и ягоды, а также личинки насекомых, мед диких пчел, яйца птиц.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# код телеграмма\n",
    "import logging\n",
    "\n",
    "from telegram import Update, ForceReply\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "\n",
    "# Enable logging\n",
    "#logging.basicConfig(\n",
    "#    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
    "#)\n",
    "\n",
    "#logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Define a few command handlers. These usually take the two arguments update and\n",
    "# context.\n",
    "def start(update: Update, context: CallbackContext) -> None:\n",
    "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
    "    user = update.effective_user\n",
    "    update.message.reply_markdown_v2(\n",
    "        fr'Hi {user.mention_markdown_v2()}\\!',\n",
    "        reply_markup=ForceReply(selective=True),\n",
    "    )\n",
    "\n",
    "\n",
    "def help_command(update: Update, context: CallbackContext) -> None:\n",
    "    \"\"\"Send a message when the command /help is issued.\"\"\"\n",
    "    update.message.reply_text('Help!')\n",
    "\n",
    "\n",
    "def echo(update: Update, context: CallbackContext) -> None:\n",
    "    \"\"\"Echo the user message.\"\"\"\n",
    "    print('update.message.text:', update.message.text)\n",
    "    try:\n",
    "        answer = main_bot(update.message.text)\n",
    "    except:\n",
    "        answer = \"Что-то пошло не так ;(\"\n",
    "    \n",
    "    try:        \n",
    "        update.message.reply_text(answer)\n",
    "    except:\n",
    "        answer = \"Что-то сломалось. Извините ;(\"\n",
    "        update.message.reply_text(answer)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Start the bot.\"\"\"\n",
    "    # Create the Updater and pass it your bot's token.\n",
    "    updater = Updater(\"2130329456:AAGRRUymCdLRgfm40dOBgOIyNJdwzDjRN10\")\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "    # on different commands - answer in Telegram\n",
    "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
    "    dispatcher.add_handler(CommandHandler(\"help\", help_command))\n",
    "\n",
    "    # on non command i.e message - echo the message on Telegram\n",
    "    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))\n",
    "\n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "\n",
    "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n",
    "    # SIGTERM or SIGABRT. This should be used most of the time, since\n",
    "    # start_polling() is non-blocking and will stop the bot gracefully.\n",
    "    updater.idle()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import enchant\n",
    "import difflib\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# проверка грамматики\n",
    "def spell_check (text):\n",
    "    list_words = word_tokenize(text)   \n",
    "\n",
    "    correct_phrase = ''\n",
    "    \n",
    "    for word in list_words:\n",
    "        sim = dict()\n",
    "        dictionary = enchant.Dict(\"ru_RU\")\n",
    "        suggestions = set(dictionary.suggest(word))\n",
    "        #print(suggestions)\n",
    "\n",
    "        for word1 in suggestions:\n",
    "            #print(word)\n",
    "            if len(word1.split()) == 1:\n",
    "                measure = difflib.SequenceMatcher(None, word, word1).ratio()\n",
    "            else:\n",
    "                measure = 0\n",
    "            sim[measure] = word1\n",
    "        if max(sim.keys()) > 0.9:\n",
    "            correct_phrase += sim[max(sim.keys())]+' '\n",
    "        else:\n",
    "            correct_phrase += word+' '\n",
    "        #print(word,' --> ',sim)\n",
    "        #print()\n",
    "    print(\"Проверка написания: \", correct_phrase)\n",
    "    return correct_phrase\n",
    "\n",
    "\n",
    "\n",
    "def main_bot_test():    \n",
    "    input_text = input('Введите запрос или нажмите Enter для выхода: ')       \n",
    "    #input_text = spell_check (input_text) #добавлена 23.11  \n",
    "       \n",
    "    while input_text:   \n",
    "        \n",
    "        #print('начальное время:', start)\n",
    "        response = main_bot(input_text)\n",
    "        \n",
    "        input_text = input('Введите запрос или нажмите Enter для выхода: ')\n",
    "    #print('До свидания')\n",
    "    bye_text = random.choice(BOT_CONFIG['intents']['by_seeyou']['responses'])\n",
    "    #text2voice(bye_text)                     \n",
    "    print(bye_text)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестовый запуск"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "main_bot_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "привет"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
